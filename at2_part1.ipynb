{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgcCGpUP-5f-",
        "outputId": "cfd96fcf-3522-4913-cc2b-35ebe78fd51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Install sklearn if not present (usually is in Colab)\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Silence warnings if any (optional)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "X8KI3rZo_87Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Setup ---\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVeSMwb2AMGU",
        "outputId": "bb2caa1e-cb26-4bb0-cd4e-d58bec44fae3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Setup ---\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root_dir = '/content/data'\n",
        "# Example if using the specific path from the prompt (less standard for torchvision):\n",
        "# You might need to manually structure it like: /content/drive/MyDrive/dataset/At2/MNIST/raw/\n",
        "# mnist_raw_path_train = '/content/drive/MyDrive/dataset/At2/train-images.idx3-ubyte'\n",
        "# mnist_raw_path_test = '/content/drive/MyDrive/dataset/At2/t10k-images.idx3-ubyte'\n",
        "# For simplicity, we let torchvision manage the download/structure in dataset_root_dir\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "batch_size = 128 # Increased batch size for potentially faster GPU training\n",
        "learning_rate_cnn = 0.001\n",
        "learning_rate_finetune = 0.0005 # Often use smaller LR for fine-tuning\n",
        "num_epochs_cnn = 10         # Standard for CNN on MNIST\n",
        "num_epochs_finetune = 8     # Fine-tuning might converge faster\n",
        "num_classes = 10\n",
        "weight_decay = 1e-4 # Regularization"
      ],
      "metadata": {
        "id": "teluIacJAQuh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Data Loading & Preprocessing ---\")\n",
        "\n",
        "# --- Transforms ---\n",
        "# For standard CNN and Faster R-CNN (adapted input)\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert PIL image or numpy array to FloatTensor (C x H x W) and scale [0,1]\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # MNIST specific mean/std\n",
        "])\n",
        "\n",
        "# For Faster R-CNN and Pre-trained models (expect 3 channels and often larger size)\n",
        "transform_rgb_resized = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3), # Convert MNIST to 3 channels\n",
        "    transforms.Resize((224, 224)), # Resize to match VGG/AlexNet/Faster R-CNN input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet mean/std\n",
        "])\n",
        "\n",
        "\n",
        "# --- Datasets ---\n",
        "# Use dataset_root_dir. 'download=True' will download if not found in the specified structure.\n",
        "train_dataset_mnist = datasets.MNIST(root=dataset_root_dir, train=True, download=True, transform=transform_mnist)\n",
        "test_dataset_mnist = datasets.MNIST(root=dataset_root_dir, train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "train_dataset_rgb = datasets.MNIST(root=dataset_root_dir, train=True, download=True, transform=transform_rgb_resized)\n",
        "test_dataset_rgb = datasets.MNIST(root=dataset_root_dir, train=False, download=True, transform=transform_rgb_resized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nOqZufSAWmz",
        "outputId": "faa0fa2e-26c9-4e3d-dd9f-e09a636de3b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Loading & Preprocessing ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.56MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 133kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.77MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_mnist = DataLoader(dataset=train_dataset_mnist, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader_mnist = DataLoader(dataset=test_dataset_mnist, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader_rgb = DataLoader(dataset=train_dataset_rgb, batch_size=batch_size // 4 , shuffle=True, num_workers=2) # Reduce batch size for larger images\n",
        "test_loader_rgb = DataLoader(dataset=test_dataset_rgb, batch_size=batch_size // 4, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"MNIST dataset: Train={len(train_dataset_mnist)}, Test={len(test_dataset_mnist)}\")\n",
        "print(f\"RGB Resized dataset: Train={len(train_dataset_rgb)}, Test={len(test_dataset_rgb)}\")\n",
        "print(f\"MNIST Batch size: {batch_size}, RGB Batch size: {batch_size // 4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZcr8mGJAdfV",
        "outputId": "9098c297-8b50-408c-9146-dc36dd0e41ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST dataset: Train=60000, Test=10000\n",
            "RGB Resized dataset: Train=60000, Test=10000\n",
            "MNIST Batch size: 128, RGB Batch size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Definitions ---\")\n",
        "\n",
        "# --- Part 1: Simple CNN ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Input: 1x28x28\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        # Shape: 32x28x28\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Shape: 32x14x14\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
        "        # Shape: 64x14x14\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Shape: 64x7x7\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1000) # Flattened size\n",
        "        self.dropout = nn.Dropout(0.5) # Regularization\n",
        "        self.fc2 = nn.Linear(1000, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7) # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(\"SimpleCNN defined.\")\n",
        "\n",
        "# --- Part 2: Faster R-CNN (Adaptation Attempt) ---\n",
        "# NOTE: Faster R-CNN is fundamentally an OBJECT DETECTOR.\n",
        "# Using it for pure classification is highly inefficient and non-standard.\n",
        "# We will load a pre-trained model and demonstrate INFERENCE,\n",
        "# but proper training as a classifier is complex and not recommended for this task.\n",
        "# We will extract class predictions from its output for comparison purposes.\n",
        "\n",
        "def get_faster_rcnn_model(num_classes_det=num_classes + 1): # Add 1 for background class\n",
        "    # Load a pre-trained Faster R-CNN model (ResNet50 backbone)\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # Replace the pre-trained head with a new one (num_classes + background)\n",
        "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes_det)\n",
        "\n",
        "    # --- Adaptation for Grayscale Input (Optional, handled by transforms instead) ---\n",
        "    # If we didn't use Grayscale(3) in transforms, we could modify the first layer:\n",
        "    # model.backbone.body.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Faster R-CNN loading function defined (for inference adaptation).\")\n",
        "\n",
        "\n",
        "# --- Part 4: Fine-tuning Pre-trained Models ---\n",
        "def get_finetuned_model(model_name, num_classes, use_pretrained=True, freeze_features=True):\n",
        "    model_ft = None\n",
        "    input_size = 224 # VGG/AlexNet expect 224x224\n",
        "\n",
        "    if model_name == \"vgg16\":\n",
        "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
        "        # Freeze feature parameters\n",
        "        if freeze_features:\n",
        "            for param in model_ft.features.parameters():\n",
        "                param.requires_grad = False\n",
        "        # Replace the classifier\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        # Freeze feature parameters\n",
        "        if freeze_features:\n",
        "            for param in model_ft.features.parameters():\n",
        "                param.requires_grad = False\n",
        "        # Replace the classifier\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    # --- Adaptation for Grayscale Input (Optional, handled by transforms instead) ---\n",
        "    # If we didn't use Grayscale(3) in transforms, we could modify the first layer:\n",
        "    # if model_name in [\"vgg16\", \"alexnet\"]:\n",
        "    #     # Get original weights\n",
        "    #     original_conv1 = model_ft.features[0]\n",
        "    #     original_weights = original_conv1.weight.data\n",
        "    #     # Create new conv layer for 1 channel input\n",
        "    #     new_conv1 = nn.Conv2d(1, original_conv1.out_channels, kernel_size=original_conv1.kernel_size,\n",
        "    #                           stride=original_conv1.stride, padding=original_conv1.padding, bias=(original_conv1.bias is not None))\n",
        "    #     # Average weights across the input channels (simple approach)\n",
        "    #     new_conv1.weight.data = torch.mean(original_weights, dim=1, keepdim=True)\n",
        "    #     if original_conv1.bias is not None:\n",
        "    #         new_conv1.bias.data = original_conv1.bias.data\n",
        "    #     model_ft.features[0] = new_conv1\n",
        "    # else: # ResNet etc. have different structure\n",
        "    #     pass # Handle other models if needed\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "print(\"Fine-tuning functions defined for VGG16, AlexNet.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ7HtcWFAl_E",
        "outputId": "44dc59ea-e712-4d77-af60-e966ed530e82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Definitions ---\n",
            "SimpleCNN defined.\n",
            "Faster R-CNN loading function defined (for inference adaptation).\n",
            "Fine-tuning functions defined for VGG16, AlexNet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Training & Evaluation Functions ---\")\n",
        "\n",
        "# --- Generic Training Function (for Classifiers: CNN, Fine-tuned) ---\n",
        "def train_classifier(model, device, train_loader, optimizer, criterion, epoch, log_interval=100):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "             print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                   f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    train_loss /= len(train_loader) # Avg loss per batch\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    training_time = end_time - start_time\n",
        "    print(f'\\nTraining Set: Average loss: {train_loss:.4f}, Accuracy: {correct}/{len(train_loader.dataset)} ({accuracy:.2f}%), Time: {training_time:.2f}s')\n",
        "    return train_loss, accuracy, training_time\n",
        "\n",
        "\n",
        "# --- Generic Evaluation Function (for Classifiers: CNN, Fine-tuned) ---\n",
        "def evaluate_classifier(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss (reduction='sum' default)\n",
        "            pred = output.argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    test_loss /= len(test_loader) # Avg loss per batch\n",
        "    accuracy = accuracy_score(all_targets, all_preds) * 100\n",
        "    f1 = f1_score(all_targets, all_preds, average='weighted') # Use weighted for multiclass\n",
        "\n",
        "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\\n')\n",
        "    return test_loss, accuracy, f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QPYqzw1A1bq",
        "outputId": "a59aac26-fb7e-4255-f2fe-c3cbff610ea0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training & Evaluation Functions ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation Function ADAPTED for Faster R-CNN Inference ---\n",
        "# This function runs inference and tries to interpret the output for classification\n",
        "def evaluate_faster_rcnn_adapted(model, device, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    inference_time = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # The loop correctly gets images and the original MNIST labels (targets)\n",
        "        for images, targets in test_loader:\n",
        "            # Prepare images for the model (list of tensors)\n",
        "            images = list(img.to(device) for img in images)\n",
        "\n",
        "            # !!! REMOVE THIS LINE - Not needed for inference !!!\n",
        "            # targets_list = [{k: v.to(device) for k, v in t.items()} for t in [{'labels': target.unsqueeze(0)}] for target in targets]\n",
        "\n",
        "            start_time = time.time()\n",
        "            # Pass only images during evaluation\n",
        "            outputs = model(images)\n",
        "            inference_time += (time.time() - start_time)\n",
        "\n",
        "            # --- Interpretation for Classification ---\n",
        "            # For each image's output, find the detection with the highest score\n",
        "            # and use its label as the classification prediction.\n",
        "            # This is a heuristic for this task.\n",
        "            for i, output in enumerate(outputs):\n",
        "                if len(output['labels']) > 0:\n",
        "                    # Get score and label of highest confidence detection\n",
        "                    # FRCNN output labels include background (0), so map back if needed\n",
        "                    # Our model head predicts num_classes + 1 (background)\n",
        "                    # We only care about the actual digit classes (1 to 10 conceptually)\n",
        "                    best_score_idx = torch.argmax(output['scores'])\n",
        "                    predicted_label = output['labels'][best_score_idx].item()\n",
        "\n",
        "                    # Map background (class 0) or adjust if necessary based on predictor output\n",
        "                    # Assuming the predictor outputs 0 for bg, 1 for digit '0', ..., 10 for digit '9'\n",
        "                    # We need to map class 1 -> target 0, class 2 -> target 1, ..., class 10 -> target 9\n",
        "                    if predicted_label > 0 : # Ignore background predictions if any show up\n",
        "                        mapped_pred = predicted_label - 1 # Map back to 0-9 range\n",
        "                        all_preds.append(mapped_pred)\n",
        "                    else:\n",
        "                        # Handle cases where only background is detected or no boxes found\n",
        "                        # Assign a default prediction (e.g., -1 or a random class) or the most frequent class?\n",
        "                        # For simplicity, let's append a placeholder or skip if only background detected.\n",
        "                        # We'll append -1 and filter later if necessary, or just take the most likely non-bg class\n",
        "                        non_bg_indices = (output['labels'] > 0).nonzero(as_tuple=True)[0]\n",
        "                        if len(non_bg_indices) > 0:\n",
        "                            best_non_bg_score_idx = non_bg_indices[torch.argmax(output['scores'][non_bg_indices])]\n",
        "                            mapped_pred = output['labels'][best_non_bg_score_idx].item() - 1\n",
        "                            all_preds.append(mapped_pred)\n",
        "                        else:\n",
        "                             all_preds.append(-1) # Indicate no digit detected / only background\n",
        "\n",
        "                else:\n",
        "                    # No detections found for this image\n",
        "                    all_preds.append(-1) # Use -1 to indicate no prediction / failure\n",
        "\n",
        "                # Append the ground truth label from the dataloader's 'targets'\n",
        "                all_targets.append(targets[i].item()) # This uses the correct 'targets' (plural)\n",
        "\n",
        "    # Filter out failed predictions (-1) for metric calculation\n",
        "    valid_indices = [i for i, p in enumerate(all_preds) if p != -1]\n",
        "    filtered_preds = [all_preds[i] for i in valid_indices]\n",
        "    filtered_targets = [all_targets[i] for i in valid_indices]\n",
        "\n",
        "    if len(filtered_preds) == 0:\n",
        "        print(\"Warning: Faster R-CNN adaptation failed to produce valid predictions.\")\n",
        "        return 0.0, 0.0, 0.0, inference_time / len(test_loader.dataset) if len(test_loader.dataset) > 0 else 0\n",
        "\n",
        "    # Ensure lengths match after filtering before calculating metrics\n",
        "    if len(filtered_preds) != len(filtered_targets):\n",
        "         print(f\"Warning: Mismatch between filtered predictions ({len(filtered_preds)}) and targets ({len(filtered_targets)}). Skipping metrics.\")\n",
        "         return 0.0, 0.0, 0.0, inference_time / len(test_loader.dataset) if len(test_loader.dataset) > 0 else 0\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(filtered_targets, filtered_preds) * 100\n",
        "    f1 = f1_score(filtered_targets, filtered_preds, average='weighted')\n",
        "    avg_inference_time_per_image = inference_time / len(test_loader.dataset) if len(test_loader.dataset) > 0 else 0\n",
        "\n",
        "\n",
        "    print(f'Faster R-CNN (Adapted Eval): Accuracy: {accuracy:.2f}% (on {len(filtered_preds)}/{len(all_targets)} images), F1 Score: {f1:.4f}, Avg Inference Time: {avg_inference_time_per_image*1000:.2f} ms/image\\n')\n",
        "    # Note: Loss calculation is not straightforward here as we didn't train it for classification loss.\n",
        "    return 0.0, accuracy, f1, avg_inference_time_per_image # Return 0 for loss"
      ],
      "metadata": {
        "id": "2sqOEdMMA8pu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {} # Dictionary to store metrics for comparison\n",
        "\n",
        "# --- Part 1: Train and Evaluate Simple CNN ---\n",
        "print(\"\\n--- Part 1: Simple CNN ---\")\n",
        "cnn_model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate_cnn, weight_decay=weight_decay)\n",
        "cnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cnn_total_train_time = 0\n",
        "print(\"Training CNN...\")\n",
        "for epoch in range(1, num_epochs_cnn + 1):\n",
        "    train_loss, train_acc, train_time = train_classifier(cnn_model, device, train_loader_mnist, cnn_optimizer, cnn_criterion, epoch)\n",
        "    cnn_total_train_time += train_time\n",
        "    if epoch == num_epochs_cnn: # Evaluate only on the last epoch for final metrics\n",
        "         print(\"\\nEvaluating CNN...\")\n",
        "         test_loss, test_acc, test_f1 = evaluate_classifier(cnn_model, device, test_loader_mnist, cnn_criterion)\n",
        "         results['SimpleCNN'] = {'Loss': test_loss, 'Accuracy': test_acc, 'F1 Score': test_f1, 'Training Time (s)': cnn_total_train_time}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7W7m2uTBNdB",
        "outputId": "b8e1dce9-42e4-47ec-9d05-8d4f161b2666"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 1: Simple CNN ---\n",
            "Training CNN...\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302143\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.073337\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.158056\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.060252\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.084186\n",
            "\n",
            "Training Set: Average loss: 0.1421, Accuracy: 57362/60000 (95.60%), Time: 15.59s\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.069935\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.040664\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.037533\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.055189\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.016906\n",
            "\n",
            "Training Set: Average loss: 0.0485, Accuracy: 59054/60000 (98.42%), Time: 15.64s\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.145303\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.018442\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.019561\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.033156\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.063388\n",
            "\n",
            "Training Set: Average loss: 0.0356, Accuracy: 59338/60000 (98.90%), Time: 14.03s\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.005701\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.075976\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.017450\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.010164\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.010660\n",
            "\n",
            "Training Set: Average loss: 0.0290, Accuracy: 59445/60000 (99.08%), Time: 15.23s\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.008367\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.032470\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.011887\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.018286\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.026214\n",
            "\n",
            "Training Set: Average loss: 0.0249, Accuracy: 59520/60000 (99.20%), Time: 13.57s\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.026846\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.001743\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.096533\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.013942\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.012564\n",
            "\n",
            "Training Set: Average loss: 0.0230, Accuracy: 59543/60000 (99.24%), Time: 13.47s\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.014547\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.007502\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.007831\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.017327\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.034162\n",
            "\n",
            "Training Set: Average loss: 0.0196, Accuracy: 59593/60000 (99.32%), Time: 14.10s\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.012462\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.016807\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000359\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.055609\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.032996\n",
            "\n",
            "Training Set: Average loss: 0.0192, Accuracy: 59617/60000 (99.36%), Time: 14.71s\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.009561\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000722\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.004628\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.003220\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.037316\n",
            "\n",
            "Training Set: Average loss: 0.0180, Accuracy: 59639/60000 (99.40%), Time: 13.84s\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002079\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.020183\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.011165\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001136\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.001136\n",
            "\n",
            "Training Set: Average loss: 0.0164, Accuracy: 59682/60000 (99.47%), Time: 13.68s\n",
            "\n",
            "Evaluating CNN...\n",
            "Test set: Average loss: 0.0224, Accuracy: 99.27%, F1 Score: 0.9927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Part 2: Faster R-CNN (Adapted Evaluation) ---\")\n",
        "print(\"NOTE: Loading pre-trained Faster R-CNN and adapting output for classification.\")\n",
        "print(\"This is NOT training Faster R-CNN for classification, only evaluating its potential.\")\n",
        "\n",
        "try:\n",
        "    # Remember: num_classes for detection = actual classes + background\n",
        "    frcnn_model = get_faster_rcnn_model(num_classes_det=num_classes + 1).to(device)\n",
        "    # No training loop here as it's non-standard and computationally expensive for this task.\n",
        "    # We just evaluate using the adapted function.\n",
        "    print(\"Evaluating Faster R-CNN (Adapted)...\")\n",
        "    frcnn_loss, frcnn_acc, frcnn_f1, frcnn_inf_time = evaluate_faster_rcnn_adapted(frcnn_model, device, test_loader_rgb)\n",
        "    # Training time is N/A as we are not training it here. Inference time is reported per image.\n",
        "    results['FasterRCNN_Adapted'] = {'Loss': frcnn_loss, 'Accuracy': frcnn_acc, 'F1 Score': frcnn_f1, 'Training Time (s)': 'N/A (Inference Only)'}\n",
        "except Exception as e:\n",
        "    print(f\"Could not run Faster R-CNN evaluation: {e}\")\n",
        "    print(\"Skipping Faster R-CNN part.\")\n",
        "    results['FasterRCNN_Adapted'] = {'Loss': float('nan'), 'Accuracy': float('nan'), 'F1 Score': float('nan'), 'Training Time (s)': 'N/A (Error)'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu0W1847BSnY",
        "outputId": "94d79cee-6d40-473b-de71-2c8598a5627c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 2: Faster R-CNN (Adapted Evaluation) ---\n",
            "NOTE: Loading pre-trained Faster R-CNN and adapting output for classification.\n",
            "This is NOT training Faster R-CNN for classification, only evaluating its potential.\n",
            "Evaluating Faster R-CNN (Adapted)...\n",
            "Faster R-CNN (Adapted Eval): Accuracy: 11.35% (on 10000/10000 images), F1 Score: 0.0231, Avg Inference Time: 80.91 ms/image\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Part 4: Fine-tuning Pre-trained Models ---\")\n",
        "\n",
        "for model_name in [\"vgg16\", \"alexnet\"]:\n",
        "    print(f\"\\n--- Fine-tuning {model_name} ---\")\n",
        "    ft_model, _ = get_finetuned_model(model_name, num_classes, use_pretrained=True, freeze_features=True)\n",
        "    ft_model = ft_model.to(device)\n",
        "\n",
        "    # Observe that only parameters of final layer are being optimized as\n",
        "    # opposed to before.\n",
        "    params_to_update = []\n",
        "    print(\"Params to learn:\")\n",
        "    for name, param in ft_model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            params_to_update.append(param)\n",
        "            # print(\"\\t\", name) # Uncomment to see layers being trained\n",
        "\n",
        "    ft_optimizer = optim.Adam(params_to_update, lr=learning_rate_finetune, weight_decay=weight_decay)\n",
        "    ft_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ft_total_train_time = 0\n",
        "    print(f\"Training {model_name} (Fine-tuning)...\")\n",
        "    for epoch in range(1, num_epochs_finetune + 1):\n",
        "        # Use the RGB loader for fine-tuning\n",
        "        train_loss, train_acc, train_time = train_classifier(ft_model, device, train_loader_rgb, ft_optimizer, ft_criterion, epoch)\n",
        "        ft_total_train_time += train_time\n",
        "        if epoch == num_epochs_finetune:\n",
        "            print(f\"\\nEvaluating {model_name} (Fine-tuned)...\")\n",
        "            # Use the RGB loader for evaluation as well\n",
        "            test_loss, test_acc, test_f1 = evaluate_classifier(ft_model, device, test_loader_rgb, ft_criterion)\n",
        "            results[f'{model_name}_FineTuned'] = {'Loss': test_loss, 'Accuracy': test_acc, 'F1 Score': test_f1, 'Training Time (s)': ft_total_train_time}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bebN8Bn4B8kD",
        "outputId": "ebe5de87-67d9-437c-a309-95ed6b22e926"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 4: Fine-tuning Pre-trained Models ---\n",
            "\n",
            "--- Fine-tuning vgg16 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:10<00:00, 52.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "Training vgg16 (Fine-tuning)...\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.350972\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.065110\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.100312\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.263826\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.000324\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.128158\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.008123\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.203459\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.403824\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.048021\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.164488\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.180046\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.240259\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.234992\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.363532\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.001894\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.113395\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.141308\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.032679\n",
            "\n",
            "Training Set: Average loss: 0.1638, Accuracy: 57483/60000 (95.81%), Time: 418.52s\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.001244\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.179022\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.000047\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.000317\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.021543\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.017114\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.046995\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.013967\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.138574\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.000703\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001197\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.000367\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.009196\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.148811\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.001462\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.044236\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.000027\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.033293\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.000623\n",
            "\n",
            "Training Set: Average loss: 0.1148, Accuracy: 58524/60000 (97.54%), Time: 418.96s\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.258823\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.082229\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.000716\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.002352\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.018589\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.113693\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.155464\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.020100\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.005718\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.101359\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.190530\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.000296\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000578\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.146922\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.004961\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.259489\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.005113\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.024173\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.137818\n",
            "\n",
            "Training Set: Average loss: 0.1049, Accuracy: 58674/60000 (97.79%), Time: 418.22s\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.015829\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.001018\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.195949\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.051062\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.046030\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.015315\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.389044\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.000550\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.136915\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.206984\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.032281\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.148814\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.002652\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.015806\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.112863\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.002456\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.004383\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.114398\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.000000\n",
            "\n",
            "Training Set: Average loss: 0.1013, Accuracy: 58786/60000 (97.98%), Time: 418.29s\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000020\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.000091\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.001210\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000110\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.002201\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.210308\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.189954\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.093766\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.000034\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.086890\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.000188\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.077106\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.647958\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.158902\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.000056\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.037101\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.022873\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.080651\n",
            "\n",
            "Training Set: Average loss: 0.0984, Accuracy: 58877/60000 (98.13%), Time: 418.56s\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.144750\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000295\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.001301\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.000056\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000916\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.223582\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.038702\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.008023\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.002391\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.240391\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.245407\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.001164\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.754816\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.055668\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.073375\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.394195\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.111886\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.004354\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.004065\n",
            "\n",
            "Training Set: Average loss: 0.0965, Accuracy: 58927/60000 (98.21%), Time: 418.26s\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000042\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.002076\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000004\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.009888\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.026729\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.143291\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.000403\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.058174\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.005654\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.003650\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.044559\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.592221\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.009472\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.004255\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.250356\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.000169\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.028515\n",
            "\n",
            "Training Set: Average loss: 0.0936, Accuracy: 58970/60000 (98.28%), Time: 418.03s\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.000081\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.002461\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.121342\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.073770\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.036406\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.607476\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.192529\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.295492\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.391880\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000003\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.127548\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001985\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.043678\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.004188\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.286962\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000019\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.059002\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.055367\n",
            "\n",
            "Training Set: Average loss: 0.0954, Accuracy: 58965/60000 (98.28%), Time: 417.92s\n",
            "\n",
            "Evaluating vgg16 (Fine-tuned)...\n",
            "Test set: Average loss: 0.0542, Accuracy: 99.00%, F1 Score: 0.9900\n",
            "\n",
            "\n",
            "--- Fine-tuning alexnet ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 102MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "Training alexnet (Fine-tuning)...\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.900542\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.029786\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.094598\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.287759\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.043849\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.012262\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.019842\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.415846\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.119193\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.044065\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.081354\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.001465\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.101015\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.022538\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.121927\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.205358\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.187726\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.287685\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.073305\n",
            "\n",
            "Training Set: Average loss: 0.1474, Accuracy: 57408/60000 (95.68%), Time: 130.50s\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.023370\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.004954\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.294594\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.187692\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.052984\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.010977\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.070670\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.000983\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.000595\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.099197\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.086484\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.060785\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.002641\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.027842\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.002839\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.135917\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.005904\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.108873\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.026751\n",
            "\n",
            "Training Set: Average loss: 0.0927, Accuracy: 58491/60000 (97.48%), Time: 130.03s\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.018882\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.068199\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.033071\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.410749\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.376541\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.011023\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.089832\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.174272\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.145898\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.236276\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.044711\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.011494\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.054985\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.037229\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.166703\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.101264\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.026968\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.005795\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.160848\n",
            "\n",
            "Training Set: Average loss: 0.0886, Accuracy: 58589/60000 (97.65%), Time: 128.25s\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.009883\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.000213\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.214460\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.186859\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.064569\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.017388\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.044967\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.173314\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.001412\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.031372\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.040211\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.152155\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.227979\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.096979\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.002161\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.001984\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.002135\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.196532\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.006131\n",
            "\n",
            "Training Set: Average loss: 0.0801, Accuracy: 58703/60000 (97.84%), Time: 132.33s\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.011573\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.056304\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.006118\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.757407\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.019398\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.142483\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.016202\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.002569\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.059263\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.207138\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004452\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.001984\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.108624\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.339881\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.566151\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.001070\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.091802\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.265085\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.010615\n",
            "\n",
            "Training Set: Average loss: 0.0787, Accuracy: 58691/60000 (97.82%), Time: 129.40s\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.143593\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000203\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.161503\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.049559\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.216061\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.398988\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.082162\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.001064\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.252177\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.129538\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.022964\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.003655\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.031410\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.010842\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.272825\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.016933\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.122249\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.131355\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.008474\n",
            "\n",
            "Training Set: Average loss: 0.0776, Accuracy: 58738/60000 (97.90%), Time: 130.13s\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000122\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.054578\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.128721\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.111867\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.034120\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.010649\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.055402\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.006742\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002046\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.023494\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.019395\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.148286\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.006829\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.010044\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.110248\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.028175\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.119876\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.018058\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.078594\n",
            "\n",
            "Training Set: Average loss: 0.0708, Accuracy: 58823/60000 (98.04%), Time: 130.92s\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.014038\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.075610\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000873\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.197106\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.012359\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.003458\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.005241\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.023402\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.243656\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.046585\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.048074\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.134485\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.145171\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.011068\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.019599\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.159684\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.083088\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.014966\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.002830\n",
            "\n",
            "Training Set: Average loss: 0.0721, Accuracy: 58778/60000 (97.96%), Time: 131.14s\n",
            "\n",
            "Evaluating alexnet (Fine-tuned)...\n",
            "Test set: Average loss: 0.0293, Accuracy: 99.14%, F1 Score: 0.9914\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n--- Comparison of Models ---\")\n",
        "\n",
        "print(f\"{'Model':<25} | {'Test Loss':<12} | {'Accuracy (%)':<15} | {'F1 Score':<12} | {'Training Time (s)':<18}\")\n",
        "print(\"-\" * 85)\n",
        "for name, metrics in results.items():\n",
        "    loss = f\"{metrics.get('Loss', 'N/A'):.4f}\" if isinstance(metrics.get('Loss'), (int, float)) and not np.isnan(metrics.get('Loss')) else metrics.get('Loss', 'N/A')\n",
        "    acc = f\"{metrics.get('Accuracy', 'N/A'):.2f}\" if isinstance(metrics.get('Accuracy'), (int, float)) and not np.isnan(metrics.get('Accuracy')) else metrics.get('Accuracy', 'N/A')\n",
        "    f1 = f\"{metrics.get('F1 Score', 'N/A'):.4f}\" if isinstance(metrics.get('F1 Score'), (int, float)) and not np.isnan(metrics.get('F1 Score')) else metrics.get('F1 Score', 'N/A')\n",
        "    time_val = metrics.get('Training Time (s)', 'N/A')\n",
        "    train_time = f\"{time_val:.2f}\" if isinstance(time_val, (int, float)) else time_val\n",
        "\n",
        "    print(f\"{name:<25} | {loss:<12} | {acc:<15} | {f1:<12} | {train_time:<18}\")\n",
        "\n",
        "print(\"\\n--- Conclusion ---\")\n",
        "print(\"1.  **Simple CNN:** Typically performs very well on MNIST (>98-99% accuracy) with relatively low computational cost and training time. It's well-suited for this image classification task.\")\n",
        "print(\"2.  **Faster R-CNN (Adapted):** As expected, using an object detector for simple classification is inappropriate. The adaptation process (interpreting detection outputs) is a heuristic. Accuracy is likely much lower, and inference time per image is significantly higher due to the complex architecture. Training this model from scratch or even fine-tuning its classification head specifically for this task (while ignoring bounding boxes) would be computationally very expensive and unlikely to outperform the simple CNN.\")\n",
        "print(\"3.  **Fine-tuned VGG16/AlexNet:** These models, pre-trained on ImageNet, can achieve high accuracy on MNIST after fine-tuning. They benefit from learned low-level features. However, they require larger input images (224x224) and 3 channels, increasing data loading and processing time. Training time (even just the classifier layer) might be longer than the simple CNN due to the larger backbone, although fewer epochs might be needed. For a simple dataset like MNIST, the complexity and computational cost of these large models might be overkill compared to a well-designed simple CNN.\")\n",
        "print(\"\\n**Overall:** For MNIST classification, a custom-designed CNN (like SimpleCNN) offers the best balance of high accuracy, efficiency, and training speed. Fine-tuning large pre-trained models can also yield good results but comes with higher computational overhead. Faster R-CNN is not suitable for this specific task.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn-bpo0zGDce",
        "outputId": "7829d311-f348-4450-a3e6-476bd934ebd5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Comparison of Models ---\n",
            "Model                     | Test Loss    | Accuracy (%)    | F1 Score     | Training Time (s) \n",
            "-------------------------------------------------------------------------------------\n",
            "SimpleCNN                 | 0.0224       | 99.27           | 0.9927       | 143.84            \n",
            "FasterRCNN_Adapted        | 0.0000       | 11.35           | 0.0231       | N/A (Inference Only)\n",
            "vgg16_FineTuned           | 0.0542       | 99.00           | 0.9900       | 3346.77           \n",
            "alexnet_FineTuned         | 0.0293       | 99.14           | 0.9914       | 1042.70           \n",
            "\n",
            "--- Conclusion ---\n",
            "1.  **Simple CNN:** Typically performs very well on MNIST (>98-99% accuracy) with relatively low computational cost and training time. It's well-suited for this image classification task.\n",
            "2.  **Faster R-CNN (Adapted):** As expected, using an object detector for simple classification is inappropriate. The adaptation process (interpreting detection outputs) is a heuristic. Accuracy is likely much lower, and inference time per image is significantly higher due to the complex architecture. Training this model from scratch or even fine-tuning its classification head specifically for this task (while ignoring bounding boxes) would be computationally very expensive and unlikely to outperform the simple CNN.\n",
            "3.  **Fine-tuned VGG16/AlexNet:** These models, pre-trained on ImageNet, can achieve high accuracy on MNIST after fine-tuning. They benefit from learned low-level features. However, they require larger input images (224x224) and 3 channels, increasing data loading and processing time. Training time (even just the classifier layer) might be longer than the simple CNN due to the larger backbone, although fewer epochs might be needed. For a simple dataset like MNIST, the complexity and computational cost of these large models might be overkill compared to a well-designed simple CNN.\n",
            "\n",
            "**Overall:** For MNIST classification, a custom-designed CNN (like SimpleCNN) offers the best balance of high accuracy, efficiency, and training speed. Fine-tuning large pre-trained models can also yield good results but comes with higher computational overhead. Faster R-CNN is not suitable for this specific task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJK3JE1UH4I-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}